<!DOCTYPE html> <html lang="en-us"> <head> <link href="http://gmpg.org/xfn/11" rel="profile"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <meta http-equiv="content-type" content="text/html; charset=utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1"> <title> The Alkyne GC &middot; mcyoung </title> <link rel="stylesheet" href="https://mcyoung.xyz/public/css/syntax.css"> <link rel="stylesheet" href="https://mcyoung.xyz/public/css/style.css"> <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=PT+Sans:400,400italic,700|Abril+Fatface"> <link rel="shortcut icon" href="https://mcyoung.xyz/public/favicon.ico"> <link rel="alternate" type="application/rss+xml" title="RSS" href="/atom.xml"> </head> <body> <div class="sidebar"> <a href="https://mcyoung.xyz/"> <img src="https://mcyoung.xyz/public/avatar.png" alt="Yeah, I drew this. Check out my art blog." class="hide-if-mobile"/> </a> <div class="container sidebar-sticky"> <div class="sidebar-about"> <h1><a href="https://mcyoung.xyz/"> mcyoung </a></h1> <p class="lead hide-if-mobile">I'm Miguel. I write about questionable C++ and Rust code. I also have an art blog linked below. </p> </div> <hr class="hide-if-mobile"/> <nav class="sidebar-nav"> <a class="sidebar-nav-item" href="https://mcyoung.xyz/">Home</a> • <a class="sidebar-nav-item" href="/about.html">About</a> • <a class="sidebar-nav-item" href="/posts.html">Posts</a> • <a class="sidebar-nav-item" href="/tags.html">Tags</a> </nav> <nav class="sidebar-nav"> <a class="sidebar-nav-item" href="https://art.mcyoung.xyz/">Art</a> • <a class="sidebar-nav-item" href="https://github.com/mcy">GH</a> • <a class="sidebar-nav-item" href="https://twitter.com/DrawsMiguel">Twt</a> • <a class="sidebar-nav-item" href="https://mcyoung.xyz/public/resume.pdf">Resumé</a> </nav> <br class="hide-if-mobile"/> <p class="hide-if-mobile">&copy; 2022 Miguel Young de la Sota <br/> <a href="https://creativecommons.org/licenses/by-sa/4.0/legalcode">CC BY-SA</a></p> </div> </div> <div class="content container"><div class="post"> <span class="post-meta"> <span> <a href="https://mcyoung.xyz/tags.html#dark-arts">#dark-arts</a> <a href="https://mcyoung.xyz/tags.html#pointers">#pointers</a> </span> <span> Soon™ </span> </span> <h1 class="post-title"><a href="/wip/alkyne-gc/"> The Alkyne GC </a></h1> <p><a href="https://github.com/mcy/alkyne">Alkyne</a> is a scripting language I built a couple of years ago for generating configuration blobs. Its interpreter is a naive AST walker<sup id="fnref:ast-walker" role="doc-noteref"><a href="#fn:ast-walker" class="footnote" rel="footnote">1</a></sup> that uses ARC<sup id="fnref:arc" role="doc-noteref"><a href="#fn:arc" class="footnote" rel="footnote">2</a></sup> for memory management, so it’s pretty slow, and I’ve been gradually writing a <a href="https://github.com/mcy/alkyne/tree/new-engine">new evaluation engine</a> for it.</p> <p>This post isn’t about Alkyne itself, that’s for another day. For now, I’d like to write down some notes for the GC I wrote<sup id="fnref:src" role="doc-noteref"><a href="#fn:src" class="footnote" rel="footnote">3</a></sup> for it, and more generally provide an introduction to memory allocators (especially those that would want to collude with a GC).</p> <h2 id="trailhead"><a href="#trailhead">Trailhead</a></h2> <p>The Alkyne GC is solving a very specific problem, which allows us to limit what it actually needs to do. Alkyne is an “embeddable” language like JavaScript, so its heap is not intended to be big; in fact, for the benefit of memory usage optimizations, it’s ideal to use 32-bit pointers (a 4 gigabyte address space).</p> <p>The heap needs to be able to manage arbitrarily-large allocations (for lists), and allocations as small as eight bytes (for floats). Allocation should be reasonably quick, but due to the size of the heap, walking the entire heap is totally acceptable.</p> <p>Because we’re managing a fixed-size heap, we can simply ask the operating system for a contiguous block of that size up-front using the <code class="language-plaintext highlighter-rouge">mmap()</code> syscall. An Alkyne pointer is simply a 32-bit offset into this giant allocation, which can be converted to and from a genuine CPU pointer by adding or subtracting the base address of the heap.</p> <p>The OS won’t actually reserve 4GB of memory for us; it will only allocate a system page (4K) at a time. If we read or write to a particular page in the heap for the first time, the OS will only then find physical RAM to back it.</p> <p>Throughout, we’ll be working with this fixed-size heap, and won’t worry about where the memory came from.</p> <p>The Alkyne language does not have threads, so we can eschew concurrency. That said, concurrent programming and allocator design go hand in hand, and experts in one are frequently experts in the other (I’m neither! ^^).</p> <h2 id="a-heap-of-trouble"><a href="#a-heap-of-trouble">A Heap of Trouble</a></h2> <p>To build a garbage collector, we first need to build an allocator. One can “just” use the system heap as a source of pages, but most garbage collectors collude with the allocator, since they will want to use similar data structures.</p> <p>An allocator, or “memory heap” (not to be confused with a min-heap, an unrelated data structure), services requests for <em>allocations</em>: unique leases of space in the managed heap of various sizes, which last for lifetimes not known until runtime. These allocations may also be called <em>objects</em>, and a heap may be viewed as a general-purpose object pool.</p> <p>The most common API for a heap is:</p> <div class="codeblock"><figure class="highlight"><pre><code class="language-c--" data-lang="c++"><span class="k">class</span> <span class="nc">Allocator</span> <span class="p">{</span>
 <span class="nl">public:</span>
  <span class="c1">// Returns a *unique pointer* managed by this allocator</span>
  <span class="c1">// to memory as large as requested.</span>
  <span class="c1">// </span>
  <span class="c1">// Returns `nullptr` on failure.</span>
  <span class="kt">void</span><span class="o">*</span> <span class="n">Alloc</span><span class="p">(</span><span class="kt">size_t</span> <span class="n">size</span><span class="p">);</span>
  <span class="c1">// Frees a pointer returned by `Alloc` may be called at</span>
  <span class="c1">// most once.</span>
  <span class="kt">void</span> <span class="n">Free</span><span class="p">(</span><span class="kt">void</span><span class="o">*</span> <span class="n">ptr</span><span class="p">);</span>
<span class="p">};</span></code></pre></figure><div class="codeblock-buttons"><div class="codeblock-button">C++</div></div></div> <p>For simplicity, we will pretend pointer alignment does not exist, nor will we talk about “sized delete”, i.e., a version of <code class="language-plaintext highlighter-rouge">Free()</code> that accepts a size. Note that this is a class that can have data associated with it; the traditional <code class="language-plaintext highlighter-rouge">malloc()</code> and <code class="language-plaintext highlighter-rouge">free()</code> simply have global state.</p> <h3 id="the-trivial-heap"><a href="#the-trivial-heap">The Trivial Heap</a></h3> <p>Allocating memory is actually very easy. <em>Arenas</em> are the leanest and meanest in the allocator food chain; they simply don’t bother to do anything on <code class="language-plaintext highlighter-rouge">Free()</code>:</p> <div class="codeblock"><figure class="highlight"><pre><code class="language-c--" data-lang="c++"><span class="k">class</span> <span class="nc">Bump</span> <span class="p">{</span>
 <span class="nl">public:</span>
  <span class="kt">void</span><span class="o">*</span> <span class="n">Alloc</span><span class="p">(</span><span class="kt">size_t</span> <span class="n">size</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">heap_</span><span class="p">.</span><span class="n">size</span><span class="p">()</span> <span class="o">-</span> <span class="n">cursor_</span> <span class="o">&lt;</span> <span class="n">size</span><span class="p">)</span> <span class="p">{</span>
      <span class="k">return</span> <span class="nb">nullptr</span><span class="p">;</span>
    <span class="p">}</span>
    <span class="k">auto</span> <span class="n">cursor</span> <span class="o">=</span> <span class="n">cursor_</span><span class="p">;</span>
    <span class="n">cursor_</span> <span class="o">+=</span> <span class="n">size</span><span class="p">;</span>
    <span class="k">return</span> <span class="o">&amp;</span><span class="n">heap_</span><span class="p">[</span><span class="n">cursor</span><span class="p">];</span>
  <span class="p">}</span>
  <span class="kt">void</span> <span class="n">Free</span><span class="p">(</span><span class="kt">void</span><span class="o">*</span> <span class="n">ptr</span><span class="p">)</span> <span class="p">{</span>
    <span class="c1">// Nothing. :)</span>
  <span class="p">}</span>
 <span class="nl">private:</span>
  <span class="n">std</span><span class="o">::</span><span class="n">span</span><span class="o">&lt;</span><span class="kt">char</span><span class="o">&gt;</span> <span class="n">heap_</span><span class="p">;</span>
  <span class="kt">size_t</span> <span class="n">cursor_</span><span class="p">;</span>
<span class="p">};</span></code></pre></figure><div class="codeblock-buttons"><div class="codeblock-button">C++</div></div></div> <p>Arenas are very simple, but far from useless! They’re great for holding onto data that exists for the context of a “session”, such as for software that does lots of computations and then exits (a compiler) or software that handles requests from clients, where lots of data lives for the duration of the request and no longer (a webserver).</p> <p>They are not, however, good for long-running systems. Eventually the heap will be exhausted if objects are not recycled.</p> <p>Making this work turns out to be hard<sup>[citation-needed]</sup>. This is the “fundamental theorem” of allocators:</p> <blockquote> <h4 id="fundamental-theorem-of-allocators"><a href="#fundamental-theorem-of-allocators">Fundamental “Theorem” of Allocators</a></h4> <p>Handing out memory is easy. Handing it out repeatedly is hard.</p> </blockquote> <p>Thankfully, over the last fifty years we’ve mostly figured this out. Allocator designs can get pretty gnarly.</p> <h2 id="baby-steps"><a href="#baby-steps">Baby Steps</a></h2> <p>From here, we will gradually augment our allocator with more features to allow it to service all kinds of requests.</p> <h3 id="blocks-and-free-lists"><a href="#blocks-and-free-lists">Blocks and Free Lists</a></h3> <p>A core abstraction of every allocator is to break up the address space it is managing into uniform(ish) <em>blocks</em> of a convenient size. Each block will have some metadata attached to it. Blocks are organized into one or more <em>free lists</em> (stacks, effectively) of unused blocks, that can be cheaply pushed and popped from. Thus, we can enhance our arena above with a free list, making it a proper allocator:</p> <div class="codeblock"><figure class="highlight"><pre><code class="language-c--" data-lang="c++"><span class="k">class</span> <span class="nc">FreeList</span> <span class="p">{</span>
 <span class="nl">public:</span>
  <span class="k">static</span> <span class="k">constexpr</span> <span class="kt">size_t</span> <span class="n">kMaxSize</span> <span class="o">=</span> <span class="mi">128</span><span class="p">;</span>
  <span class="n">FreeList2</span><span class="p">()</span> <span class="p">{</span>
    <span class="n">heap_</span> <span class="o">=</span> <span class="cm">/* mmap() or something */</span><span class="p">;</span>

    <span class="c1">// To construct the list, we need to mark every block as freed.</span>
    <span class="k">for</span> <span class="p">(</span><span class="n">Block</span><span class="o">*</span> <span class="n">b</span> <span class="o">:</span> <span class="n">heap_</span><span class="p">)</span> <span class="p">{</span>
      <span class="n">free_list_</span><span class="p">.</span><span class="n">push_back</span><span class="p">(</span><span class="n">b</span><span class="p">);</span>
    <span class="p">}</span>
  <span class="p">}</span>

  <span class="kt">void</span><span class="o">*</span> <span class="n">Alloc</span><span class="p">(</span><span class="kt">size_t</span> <span class="n">size</span><span class="p">)</span> <span class="p">{</span>
    <span class="c1">// We can only serve a maximum size.</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">heap_</span><span class="p">.</span><span class="n">empty</span><span class="p">()</span> <span class="o">||</span> <span class="n">size</span> <span class="o">&gt;</span> <span class="n">kMaxSize</span><span class="p">)</span> <span class="p">{</span>
      <span class="k">return</span> <span class="nb">nullptr</span><span class="p">;</span>
    <span class="p">}</span>

    <span class="n">Block</span><span class="o">*</span> <span class="n">block</span> <span class="o">=</span> <span class="n">free_list_</span><span class="p">.</span><span class="n">back</span><span class="p">();</span>
    <span class="n">block</span><span class="o">-&gt;</span><span class="n">is_free</span> <span class="o">=</span> <span class="nb">false</span><span class="p">;</span>
    <span class="n">free_list_</span><span class="p">.</span><span class="n">pop</span><span class="p">();</span>

    <span class="k">return</span> <span class="n">block</span><span class="o">-&gt;</span><span class="n">data</span><span class="p">.</span><span class="n">data</span><span class="p">();</span>
  <span class="p">}</span>

  <span class="kt">void</span> <span class="n">Free</span><span class="p">(</span><span class="kt">void</span><span class="o">*</span> <span class="n">ptr</span><span class="p">)</span> <span class="p">{</span>
    <span class="c1">// Assume ptr one of ours; offset past the header.</span>
    <span class="n">Block</span><span class="o">*</span> <span class="n">block</span> <span class="o">=</span> <span class="k">reinterpret_cast</span><span class="o">&lt;</span><span class="n">Block</span><span class="o">*&gt;</span><span class="p">(</span>
      <span class="k">reinterpret_cast</span><span class="o">&lt;</span><span class="kt">char</span><span class="o">*&gt;</span><span class="p">(</span><span class="n">ptr</span><span class="p">)</span> <span class="o">-</span> <span class="n">offsetof</span><span class="p">(</span><span class="n">Block</span><span class="p">,</span> <span class="n">data</span><span class="p">));</span>

    <span class="c1">// We can do a probabilistic check here as an imperfect</span>
    <span class="c1">// defense against double-free; lots of allocators</span>
    <span class="c1">// do this.</span>
    <span class="n">assert</span><span class="p">(</span><span class="o">!</span><span class="n">block</span><span class="o">-&gt;</span><span class="n">is_free</span><span class="p">);</span>

    <span class="n">block</span><span class="o">-&gt;</span><span class="n">is_free</span> <span class="o">=</span> <span class="nb">true</span><span class="p">;</span>
    <span class="n">free_list_</span><span class="p">.</span><span class="n">push_back</span><span class="p">(</span><span class="n">block</span><span class="p">);</span>
  <span class="p">}</span>

 <span class="nl">private:</span>
  <span class="c1">// The block can contain header information in addition</span>
  <span class="c1">// to user-visible data. </span>
  <span class="k">struct</span> <span class="nc">Block</span> <span class="p">{</span>
    <span class="kt">bool</span> <span class="n">is_free</span><span class="p">;</span>
    <span class="n">std</span><span class="o">::</span><span class="n">array</span><span class="o">&lt;</span><span class="kt">char</span><span class="p">,</span> <span class="n">kMaxSize</span><span class="o">&gt;</span> <span class="n">data</span><span class="p">;</span>
  <span class="p">};</span>

  <span class="c1">// Backing store; never resized.</span>
  <span class="n">std</span><span class="o">::</span><span class="n">span</span><span class="o">&lt;</span><span class="n">Block</span><span class="o">&gt;</span> <span class="n">heap_</span><span class="p">;</span>
  <span class="c1">// Contains a block if and only if it is not allocated.</span>
  <span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">Block</span><span class="o">*&gt;</span> <span class="n">free_list_</span><span class="p">;</span>
<span class="p">};</span></code></pre></figure><div class="codeblock-buttons"><div class="codeblock-button">C++</div></div></div> <p>Allocation and freeing is O(1), yay! There are, however, serious limitations:</p> <ul> <li>We need to call an allocator to allocate the free list.</li> <li>Blocks are exactly 128 bytes; small allocations are wasteful while large ones can’t be serviced!</li> </ul> <p>The first of these is easily resolved by making the free list a linked list! The much-derided linked list is actually an extremely popular data structure for use in allocators; with a few tweaks, we can drop the separate free list by making it part of the block store. This avoids the chicken-and-egg problem of “Where does the allocator allocate its free list?”.</p> <div class="codeblock"><figure class="highlight"><pre><code class="language-c--" data-lang="c++"><span class="k">class</span> <span class="nc">KnRAlloc</span> <span class="p">{</span>
 <span class="nl">public:</span>
  <span class="k">static</span> <span class="k">constexpr</span> <span class="kt">size_t</span> <span class="n">kMaxSize</span> <span class="o">=</span> <span class="mi">128</span><span class="p">;</span>
  <span class="n">FreeList2</span><span class="p">()</span> <span class="p">{</span>
    <span class="n">heap_</span> <span class="o">=</span> <span class="cm">/* mmap() or something */</span><span class="p">;</span>

    <span class="c1">// To construct the list, we need to mark every block as freed.</span>
    <span class="k">for</span> <span class="p">(</span><span class="n">Block</span><span class="o">*</span> <span class="n">b</span> <span class="o">:</span> <span class="n">heap_</span><span class="p">)</span> <span class="p">{</span>
      <span class="n">Free</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="p">{});</span>
    <span class="p">}</span>
  <span class="p">}</span>

  <span class="kt">void</span><span class="o">*</span> <span class="n">Alloc</span><span class="p">(</span><span class="kt">size_t</span> <span class="n">size</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">free_list_</span> <span class="o">==</span> <span class="nb">nullptr</span> <span class="o">||</span> <span class="n">size</span> <span class="o">&gt;</span> <span class="n">kMaxSize</span><span class="p">)</span> <span class="p">{</span>
      <span class="k">return</span> <span class="nb">nullptr</span><span class="p">;</span>
    <span class="p">}</span>

    <span class="c1">// To allocate, we unlink the list head.</span>
    <span class="n">Block</span><span class="o">*</span> <span class="n">block</span> <span class="o">=</span> <span class="n">free_list_</span><span class="p">;</span>
    <span class="n">free_list_</span> <span class="o">=</span> <span class="n">free_list_</span><span class="o">-&gt;</span><span class="n">next</span><span class="p">;</span>
    <span class="n">block</span><span class="o">-&gt;</span><span class="n">next</span> <span class="o">=</span> <span class="nb">nullptr</span><span class="p">;</span>
    <span class="k">return</span> <span class="n">block</span><span class="p">;</span>
  <span class="p">}</span>

  <span class="kt">void</span> <span class="n">Free</span><span class="p">(</span><span class="kt">void</span><span class="o">*</span> <span class="n">ptr</span><span class="p">,</span> <span class="n">Layout</span> <span class="n">layout</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">Block</span><span class="o">*</span> <span class="n">block</span> <span class="o">=</span> <span class="cm">/* as before */</span><span class="p">;</span>
    <span class="n">assert</span><span class="p">(</span><span class="n">block</span><span class="o">-&gt;</span><span class="n">next</span> <span class="o">==</span> <span class="nb">nullptr</span><span class="p">);</span>

    <span class="c1">// To free, link the block back in.</span>
    <span class="n">block</span><span class="o">-&gt;</span><span class="n">next</span> <span class="o">=</span> <span class="n">free_list_</span><span class="p">;</span>
    <span class="n">free_list_</span> <span class="o">=</span> <span class="n">block</span><span class="p">;</span>
  <span class="p">}</span>

 <span class="nl">private:</span>
  <span class="k">struct</span> <span class="nc">Block</span> <span class="p">{</span>
    <span class="n">Block</span><span class="o">*</span> <span class="n">next</span><span class="p">;</span>
    <span class="n">std</span><span class="o">::</span><span class="n">array</span><span class="o">&lt;</span><span class="kt">char</span><span class="p">,</span> <span class="n">kMaxSize</span><span class="o">&gt;</span> <span class="n">data</span><span class="p">;</span>
  <span class="p">};</span>

  <span class="c1">// Backing store; never resized.</span>
  <span class="n">std</span><span class="o">::</span><span class="n">span</span><span class="o">&lt;</span><span class="n">Block</span><span class="o">&gt;</span> <span class="n">heap_</span><span class="p">;</span>
  <span class="n">Block</span><span class="o">*</span> <span class="n">free_list_</span> <span class="o">=</span> <span class="nb">nullptr</span><span class="p">;</span>
<span class="p">};</span></code></pre></figure><div class="codeblock-buttons"><div class="codeblock-button">C++</div></div></div> <p>The <code class="language-plaintext highlighter-rouge">free_list_</code> data structure is called an <em>intrusive linked list</em>. Elements of the list contain a pointer to the next element, rather than having it be allocated on the side. This allows a flat array of elements to double as a backing store and a stack!</p> <p>This design is a simplified version of the one found in the K&amp;R book, but it suffers from the size issue: it can’t allocate more than 128 bytes, and that’s super wasteful if you allocate small amounts!</p> <p>At this point it makes sense to dive into how Alkyne achieves this; there are <em>many</em> choices for how to do this; Alkyne is based off of things I wanted to try out at the time.</p> <p>(At this point, I won’t provide complete code samples since they’d get too big; I suggest referring to the Alkyne source, instead.)</p> <h3 id="block-splitting-the-alkyne-way"><a href="#block-splitting-the-alkyne-way">Block Splitting, the Alkyne Way</a></h3> <p>The next step is to use a block splitting/merging scheme, such as the <a href="https://en.wikipedia.org/wiki/Buddy_memory_allocation"><em>buddy system</em></a>. Alkyne does not use the buddy system, since it is a garbage-collecting heap, but it does do something similar.</p> <p>Most allocators, including Alkyne, define a <em>page</em> as the minimum quantity of memory that they operate on. For Alkyne, this is a 4K operating system page; TCMalloc, which mostly uses hugepages that are much larger than that, has 8K pages.</p> <h4 id="page-descriptors"><a href="#page-descriptors">Page Descriptors</a></h4> <p>Each page has a header called a page descriptor, or <a href="https://github.com/mcy/alkyne/blob/a62ad3b7ee70268625da640c1edeea8ff7116512/src/eval2/gc.rs#L416"><code class="language-plaintext highlighter-rouge">Pd</code></a>, that looks like this:</p> <div class="codeblock"><figure class="highlight"><pre><code class="language-rust" data-lang="rust"><span class="nd">#[repr(C)]</span>
<span class="k">struct</span> <span class="n">Pd</span> <span class="p">{</span>
  <span class="n">gc_bits</span><span class="p">:</span> <span class="nb">u64</span><span class="p">,</span>
  <span class="n">prev</span><span class="p">:</span> <span class="nb">Option</span><span class="o">&lt;</span><span class="nb">u32</span><span class="o">&gt;</span><span class="p">,</span>
  <span class="n">next</span><span class="p">:</span> <span class="nb">Option</span><span class="o">&lt;</span><span class="nb">u32</span><span class="o">&gt;</span><span class="p">,</span>
  <span class="n">len</span><span class="p">:</span> <span class="nb">u16</span><span class="p">,</span>
  <span class="n">class</span><span class="p">:</span> <span class="n">SizeClass</span><span class="p">,</span>
  <span class="c">// More fields...</span>
<span class="p">}</span></code></pre></figure><div class="codeblock-buttons"><div class="codeblock-button">Rust</div></div></div> <p><code class="language-plaintext highlighter-rouge">prev</code> and <code class="language-plaintext highlighter-rouge">next</code> are intrusive linked list pointers used for the free lists, similar to the <code class="language-plaintext highlighter-rouge">KnRAlloc</code> header. We’ll see how the other fields are used shortly.</p> <p>Because we need to maintain blocks larger than one page, we can’t have the headers be <em>part</em> of the page. Thus, we split the heap into two parts; the page descriptors, and the pages themselves. Because we know the maximum capacity of the allocator, we can reserve a couple of megabytes at the beginning of the address space to be an array of every <code class="language-plaintext highlighter-rouge">Pd</code> in order; the heap memory itself would then follow. Thus, the address space looks like this:</p> <div class="codeblock"><figure class="highlight"><pre><code class="language-text" data-lang="text">+---------------------------------------+
| Pd | Pd | Pd | Pd | Pd | Pd | Pd | Pd | \
+---------------------------------------+ |--- Page Descriptors
| Pd | Pd | Pd | Pd | Pd | Pd | Pd | Pd | |    for every page.
+---------------------------------------+ |
: ...                                   : |
+---------------------------------------+ |
| Pd | Pd | Pd | Pd | Pd | Pd | Pd | Pd | /
+---------------------------------------+  &lt;-- Heap base address.
| Page 0                                | \
|                                       | |--- 4K pages corresponding
|                                       | |    to the Pds above.
+---------------------------------------+ |    (not to scale)
| Page 1                                | |
|                                       | |
|                                       | |
+---------------------------------------+ |
: ...                                   | |
+---------------------------------------+ |
| Page N                                | |
|                                       | |
|                                       | /
+---------------------------------------+</code></pre></figure><div class="codeblock-buttons"><div class="codeblock-button">Text</div></div></div> <p>Given a pointer into a page, we can get the corresponding <code class="language-plaintext highlighter-rouge">Pd</code> by rounding down to a page boundary, computing the index of the page (relative to the heap base), and then index into the <code class="language-plaintext highlighter-rouge">Pd</code> array; this process can be reversed to convert a pointer to a <code class="language-plaintext highlighter-rouge">Pd</code> into a pointer to a page.</p> <h4 id="reams-of-pages"><a href="#reams-of-pages">Reams of Pages</a></h4> <p>Pages are organized into continuous regions called <em>reams</em> (get it?). There is a giant free list that contains every unused ream. Ream metadata is tracked by the <code class="language-plaintext highlighter-rouge">Pd</code> of its first page. <code class="language-plaintext highlighter-rouge">len</code> is the number of pages in the ream. If a ream is currently allocated for use, the <code class="language-plaintext highlighter-rouge">gc_bits</code> field is set to 1.</p> <p>To allocate N continuous pages from the free ream list:</p> <ol> <li>We walk through the free ream list, and pick the first one with at least N pages.</li> <li>We “split” it: the first N pages are returned to fulfill the request.</li> <li>The rest of the ream is put back into the free list.</li> <li>If no such ream exists, we allocate a max-sized ream<sup id="fnref:max-size" role="doc-noteref"><a href="#fn:max-size" class="footnote" rel="footnote">4</a></sup> (65536 pages), and split that as above.</li> </ol> <p>To free a ream, we just stick it back on the main free list.</p> <p>There is an obvious problem: Over time, reams will get smaller and smaller, and fragmentation will make further allocation of large reams impossible. This can be fixed by merging reams, but is not yet implemented. This would be done thus:</p> <ol> <li>Find two adjacent, unallocated reams.</li> <li>Unlink the second ream from the free list.</li> <li>Increase the length of the first ream by the number of pages in the second.</li> </ol> <p>We don’t need to do anything to the second ream’s <code class="language-plaintext highlighter-rouge">Pd</code>; by becoming part of the first ream, it is subsumed. Walking the heap requires using reams’ lengths to skip over currently-invalid <code class="language-plaintext highlighter-rouge">Pd</code>s anyways.</p> <p>We have two options for finding mergeable reams. Either we can walk the entire heap, iterating through the <code class="language-plaintext highlighter-rouge">Pd</code> array and using the <code class="language-plaintext highlighter-rouge">len</code> value to skip over non-initial <code class="language-plaintext highlighter-rouge">Pd</code>s, or, when a ream is freed, we can check that the previous and following reams are mergeable (finding the previous ream would require storing the length of a ream at its first <em>and</em> last <code class="language-plaintext highlighter-rouge">Pd</code>).</p> <p>Which merging strategy we use depends on whether we’re implementing an ordinary <code class="language-plaintext highlighter-rouge">malloc</code>-like heap or a garbage collector; in the <code class="language-plaintext highlighter-rouge">malloc</code> case, merging on free makes more sense, but merging in one shot makes more sense for Alkyne’s GC (we’ll see why in a bit).</p> <h3 id="slabs-and-size-classes"><a href="#slabs-and-size-classes">Slabs and Size Classes</a></h3> <p>A <em>slab allocator</em> is a specialized allocator that allocates a single type of object; they are quite popular in kernels as pools of commonly-used object types. The crux of a slab allocator is because everything is the same size, we <em>don’t</em> need to implement splitting and merging. The <code class="language-plaintext highlighter-rouge">KnRAlloc</code> above is essentially a very primitive slab allocator.</p> <p>Our <code class="language-plaintext highlighter-rouge">Pd</code> array is also kind of like a slab allocator; instead of mixing them in with the variably-sized blocks, they all live together with no gaps in between; entire pages are dedicated just to <code class="language-plaintext highlighter-rouge">Pd</code>s.</p> <p>The Alkyne page allocator cannot allocate pages smaller than 4K, and making them any smaller increases the relative overhead of a <code class="language-plaintext highlighter-rouge">Pd</code>. To cut down on book-keeping, we slab-allocate small objects by defining <em>size classes</em>.</p> <p>A size class is size of smaller-than-a-page object that Alkyne will allocate; other sizes are rounded up to the next size class. Entire pages are dedicated to holding just objects of the same size; these are called <em>small object pages</em>. The size class is tracked with the <code class="language-plaintext highlighter-rouge">class</code> field of the <code class="language-plaintext highlighter-rouge">Pd</code>.</p> <p>Each size class has its own free list of partially-filled small object pages of that size. The <code class="language-plaintext highlighter-rouge">gc_bits</code> field is a bitset that tracks which slots in the page are currently in-use, reducing the overhead for small objects to only a little over a single bit each!</p> <p>Allocating small objects is very fast, since the small object free lists, if not empty, will have a spot to fill that can be selected from <code class="language-plaintext highlighter-rouge">gc_bits</code> with vector instructions. If no partially-filled pages of that size exist, we can allocate a single page as usual (Alkyne maintains a separate free list for single free pages to speed this step up; most allocated objects are small).</p> <p>Alkyne’s size classes are the powers of two from 8 (the smallest possible object) to 2048. For the classes 8, 16, and 32, which would have more than 64 slots in the page, we use up to 56 bytes on the page itself to extend <code class="language-plaintext highlighter-rouge">gc_bits</code>; 8-byte pages can only hold 505 objects, instead of the full 512, a 1% overhead.</p> <p>Directly freeing an object via <code class="language-plaintext highlighter-rouge">Free()</code> is now tricky, since we do not a priori know the size. If we assume the pointer is the start of an allocation, we can find its <code class="language-plaintext highlighter-rouge">Pd</code>, by rounding down to a page boundary as before. If this page has a non-trivial size class, the <code class="language-plaintext highlighter-rouge">size</code> parameter will tell us; we can then use the difference between the pointer and the page address to find the index of the object and set its bit in <code class="language-plaintext highlighter-rouge">gc_bits</code> accordingly.</p> <p>At this point, we know whether the page just became partially full or empty, and can move it to the correct freelist accordingly.</p> <p>Size classes are an important allocator optimization. TCMalloc takes this to an <a href="https://github.com/google/tcmalloc/blob/master/tcmalloc/size_classes.cc">comical extreme</a>.</p> <h2 id="throwing-out-the-trash"><a href="#throwing-out-the-trash">Throwing out the Trash</a></h2> <p>Now that we have a fully functioning <code class="language-plaintext highlighter-rouge">Free()</code>, we can tweak how it gets called to make it into a <em>garbage collector</em>.</p> <p>Garbage collection is very different from manual memory management in that frees are performed in <em>batches</em> without cue from the user. There are no calls to <code class="language-plaintext highlighter-rouge">Free()</code>; instead, we need to figure out which calls to <code class="language-plaintext highlighter-rouge">Free()</code> we <em>can</em> make on the user’s behalf that they won’t notice (i.e., without quietly freeing pointers the user can still reach, resulting in a use-after-free bug). We need to do this as fast as we can.</p> <p>Alkyne is a “tracing GC” implementing a “mark and sweep” algorithm. Tracing GCs walk the “object graph” from a root set of known-reachable objects. Given an object <code class="language-plaintext highlighter-rouge">a</code>, it will <em>trace</em> through any data in the object that it knows is actually a GC pointer. In the object graph, <code class="language-plaintext highlighter-rouge">b</code> is reachable from <code class="language-plaintext highlighter-rouge">a</code> if one can repeatedly trace through GC pointers to get from <code class="language-plaintext highlighter-rouge">a</code> to <code class="language-plaintext highlighter-rouge">b</code>.</p> <p><em>Marking</em> consists of traversing the entire graph from a collection of reachable-by-definition values, such as things on the stack, and recording each object that is visited. Every object <em>not</em> so marked must therefore be definitely unreachable and can be reclaimed; this reclamation is called <em>sweeping</em>.</p> <p>Alkyne reverses the order of operations somewhat: it “sweeps” first and then marks, i.e., it marks every value as dead and then, as it walks the graph, marks every block as alive. It then rebuilds the free lists to reflect the new marks, allowing the blocks to be reallocated. This is sometimes called “mark and don’t sweep”, but fixing up the free lists is effectively a sweeping step.</p> <p>Alkyne is a “world-stopping” GC. It needs to pause all program execution while cleaning out the heap. It is possible to build GCs that do not do this (I believe modern HotSpot GCs very rarely stop the world), but also very difficult.</p> <h3 id="heap-armageddon-and-resurrection"><a href="#heap-armageddon-and-resurrection">Heap Armageddon and Resurrection</a></h3> <p>Delicate freeing of single objects is quite difficult, but scorching the earth is very easy. To do this, we walk the whole <code class="language-plaintext highlighter-rouge">Pd</code> array and clear every presence bit. This leaves the heap in a broken state where every pointer appears to be dangling. This is “armageddon”.</p> <p>To fix this up, we need to “resurrect” any objects we shouldn’t have killed. The roots are objects in the Alkyne interpreter stack<sup id="fnref:stack-roots" role="doc-noteref"><a href="#fn:stack-roots" class="footnote" rel="footnote">5</a></sup>. To mark an object, we convert a pointer to it into a <code class="language-plaintext highlighter-rouge">Pd</code> via the page-<code class="language-plaintext highlighter-rouge">Pd</code> correspondence, and mark it as alive by “allocating” it.</p> <p>We then use our knowledge<sup id="fnref:interpreter-knowledge" role="doc-noteref"><a href="#fn:interpreter-knowledge" class="footnote" rel="footnote">6</a></sup> of Alkyne objects’ heap layout to find pointers to other objects in the heap (for example, we can tell that we’re currently that we’re currently tracing a list). If we trace into an object and find it has been marked as allocated, we don’t recurse; this avoids infinite-looping when encountering cycles.</p> <p>At the end of this process, every reachable object will once again be alive, but anything we couldn’t reach stays dead.</p> <h3 id="instant-apocalypse"><a href="#instant-apocalypse">Instant Apocalypse</a></h3> <p>Alkyne currently does not make this optimization, but probably should.</p> <p>Rather than flipping every bit, we flip the global <em>convention</em> for whether 0 or 1 means “alive”, implemented by having a global <code class="language-plaintext highlighter-rouge">bool</code> specifying which is which at any given time; this would alternate from sweep to sweep. Thus, killing every living object is now a single operation.</p> <p>This works if the allocated bit of objects in the free lists is never read, and only ever overwritten with the “alive” value when allocated, so that all of the dead objects suddenly becoming alive isn’t noticed. This does not work with slab-allocated small objects: pages may be in a mixed state where they are partially allocated and partially freed.</p> <p>We can still make this optimization by adding a second bit that tracks whether the page contains <em>any</em> living objects, using the same convention. This allows delaying the clear of the allocated bits for small objects to when the page is visited, which also marks the whole page as alive.</p> <p>Pages that were never visited (i.e., still marked as dead) can be reclaimed as usual, ignoring the allocated bits.</p> <h3 id="free-list-reconciliation"><a href="#free-list-reconciliation">Free List Reconciliation</a></h3> <p>At this point, no pointers are dangling, but newly emptied out pages are not in the free lists they should be in. To fix this, we can walk over all <code class="language-plaintext highlighter-rouge">Pd</code>s and put them where they need to go if they’re not full. This is the kinda-but-not-really sweep phase.</p> <p>The Rust code is surprisingly simple:</p> <div class="codeblock"><figure class="highlight"><pre><code class="language-rust" data-lang="rust"><span class="k">for</span> <span class="n">pd</span> <span class="n">in</span> <span class="k">self</span><span class="py">.raw</span><span class="nf">.pds</span><span class="p">()</span><span class="nf">.filter</span><span class="p">(|</span><span class="n">pd</span><span class="p">|</span> <span class="n">pd</span><span class="nf">.is_linked</span><span class="p">())</span> <span class="p">{</span>
  <span class="k">if</span> <span class="n">pd</span><span class="nf">.is_empty</span><span class="p">()</span> <span class="p">{</span>
    <span class="n">pd</span><span class="nf">.unlink</span><span class="p">();</span>
    <span class="k">if</span> <span class="n">pd</span><span class="nf">.is_single_page</span><span class="p">()</span> <span class="p">{</span>
      <span class="k">unsafe</span> <span class="p">{</span> <span class="k">self</span><span class="py">.page_free_list</span><span class="nf">.push</span><span class="p">(</span><span class="n">pd</span><span class="p">)</span> <span class="p">}</span>
    <span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
      <span class="k">unsafe</span> <span class="p">{</span> <span class="k">self</span><span class="py">.ream_free_list</span><span class="nf">.push</span><span class="p">(</span><span class="n">pd</span><span class="p">)</span> <span class="p">}</span>
    <span class="p">}</span>
  <span class="p">}</span> <span class="k">else</span> <span class="k">if</span> <span class="n">pd</span><span class="nf">.is_full</span><span class="p">()</span> <span class="p">{</span>
    <span class="c">// GC can't make a not-full-list become full, so we don't</span>
    <span class="c">// need to move it.</span>
  <span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
    <span class="c">// Non-empty, non-full lists cannot be reams.</span>
    <span class="nd">debug_assert!</span><span class="p">(</span><span class="n">pd</span><span class="nf">.class</span><span class="p">()</span> <span class="o">!=</span> <span class="nn">SizeClass</span><span class="p">::</span><span class="n">Ream</span><span class="p">);</span>

    <span class="n">pd</span><span class="nf">.unlink</span><span class="p">();</span>
    <span class="k">unsafe</span> <span class="p">{</span>
      <span class="k">self</span><span class="py">.sized_free_lists</span><span class="p">[</span><span class="n">pd</span><span class="nf">.class</span><span class="p">()</span> <span class="k">as</span> <span class="nb">usize</span> <span class="o">-</span> <span class="mi">3</span><span class="p">]</span><span class="nf">.push</span><span class="p">(</span><span class="n">pd</span><span class="p">)</span>
    <span class="p">}</span>
  <span class="p">}</span>
<span class="p">}</span></code></pre></figure><div class="codeblock-buttons"><div class="codeblock-button">Rust</div></div></div> <p>Of course, this will also shuffle around all pages that did not become partially empty or empty while marking. If the “instant apocalypse” optimization is used, this step must still inspect every <code class="language-plaintext highlighter-rouge">Pd</code> and modify the free lists.</p> <p>However, it is a completely separate phase: all it does is find pages that did not survive the previous mark phase. This means that user code can run between the phases, reducing latency. If it turns out to be very expensive to sweep the whole heap, it can even be run less often than mark phases<sup id="fnref:if-quick-kill" role="doc-noteref"><a href="#fn:if-quick-kill" class="footnote" rel="footnote">7</a></sup>.</p> <p>This is also a great chance to merge reams, because we’re inspecting every page anyways; this is why the merging strategy depends on wanting to be a GC.</p> <p>…and that’s it! That’s garbage collection. The setup of completely owning the layout of blocks in the allocator allows us to cut down significantly on memory needed to track objects in the heap, while keeping the mark and sweep steps short and sweet. A garbage collector is like any other data structure: you pack in a lot of complexity into the invariants to make the actual operations very quick.</p> <h2 id="conclusion"><a href="#conclusion">Conclusion</a></h2> <p>Alkyne’s GC is intended to be super simple because I didn’t want to think too hard about it (even though I clearly did lmao). The GC layouts are a whole ‘nother story I have been swirling around in my head for months, which is described <a href="https://github.com/mcy/alkyne/blob/a62ad3b7ee70268625da640c1edeea8ff7116512/src/eval2/value.rs#L78">here</a>. The choices made there influenced the design of the GC itself.</p> <p>There are still many optimizations to make, but it’s a really simple but realistic GC design, and I’m pretty happy with it!</p> <h3 id="a-note-on-finalizers-tools-of-the-devil"><a href="#a-note-on-finalizers-tools-of-the-devil">A Note on Finalizers (Tools of the Devil)</a></h3> <p>Alkyne also does not provide finalizers. A finalizer is the GC equivalent of a destructor: it gets run after the GC declares an object dead. Finalizers complicate a GC significantly by their very nature; they are called in unspecified orders and can witness broken GC state; they can stall the entire program (if they are implemented to run during the GC pause in a multi-threaded GC) or else need to be called with a zombie argument that either can’t escape the finalizer or, worse, must be resurrected if it does!</p> <p>If finalizers depend on each other, they can’t be run at all, for the same reason an ARC cycle cannot be broken; this weakness of ARC is one of the major benefits of an omniscient GC.</p> <p>Java’s <a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/Object.html#finalize()">documentation for <code class="language-plaintext highlighter-rouge">Object.finalize()</code></a> is a wall of text of lies, damned lies, and ghost stories.</p> <p>I learned earlier (the week before writing this) that Go ALSO has finalizers and that they are <a href="https://pkg.go.dev/runtime#SetFinalizer">similarly cursed</a>. Go does behave somewhat more nicely (finalizers are per-value and avoid zombie problems by unconditionally resurrecting objects with a finalizer).</p> <h3 id="further-reading"><a href="#further-reading">Further Reading</a></h3> <p>Here are some other allocators that I find interesting and worth reading about, some of which have inspired elements of Alkyne’s design.</p> <p><a href="https://google.github.io/tcmalloc/design.html">TCMalloc</a> is Google’s crazy thread-caching allocator. It’s really fast and really cool, but I work for Google, so I’m biased. But it uses radix trees! Radix trees are cool!!!</p> <p>Go <a href="https://cs.opensource.google/go/go/+/master:src/runtime/mgc.go">has a garbage collector</a> that has well-known performance properties but does not perform any wild optimizations like moving, and is a world-stopping, incremental GC.</p> <p><a href="https://chromium.googlesource.com/chromium/src/+/master/third_party/blink/renderer/platform/heap/BlinkGCAPIReference.md">Oilpan</a> is the Chronimum renderer’s GC (you know, for DOM elements). It’s actually grafted onto C++ and has a very complex API reflective of the subtleties of GCs as a result.</p> <p><a href="https://www.hboehm.info/gc/">libboehm</a> is another C/C++ GC written by Hans Boehm, one of the world’s top experts on concurrency.</p> <p><a href="https://v8.dev/blog/trash-talk">Orinoco</a> is V8’s GC for the JavaScript heap (i.e., Chronimum’s <em>other</em> GC). It is a <em>generational</em> or <em>moving GC</em> that can defragment the heap over time by moving things around (and updating pointers). It also has a separate sub-GC just for short-lived objects.</p> <p><a href="https://arxiv.org/abs/1902.04738">Mesh</a> is a non-GC allocator that can do compacting via clever use of <code class="language-plaintext highlighter-rouge">mmap(2)</code>.</p> <p><a href="https://github.com/protocolbuffers/upb/blob/1cf8214e4daa1d0dd9777c987697e82c2a3c6584/upb/upb.c#L117"><code class="language-plaintext highlighter-rouge">upb_Arena</code></a> is an arena allocator that uses free-lists to allows fusing arenas together. This part of the μpb Protobuf runtime.</p> <div class="footnotes" role="doc-endnotes"> <ol> <li id="fn:ast-walker" role="doc-endnote"> <p>In other words, it uses recursion along a syntax tree, instead of a more efficient approach that compiles the program down to bytecode. <a href="#fnref:ast-walker" class="reversefootnote" role="doc-backlink">&#8617;</a></p> </li> <li id="fn:arc" role="doc-endnote"> <p><em>A</em>utomatic <em>R</em>eference <em>C</em>ounting is an automatic memory management technique where every heap allocation contains a counter of how many pointers currently point to it; once pointers go out of scope, they decrement the counter; when the counter hits zero the memory is freed.</p> <p>This is used by Python and Swift as the core memory management strategy, and provided by C++ and Rust via the <code class="language-plaintext highlighter-rouge">std::shared_ptr&lt;T&gt;</code> and <code class="language-plaintext highlighter-rouge">Arc&lt;T&gt;</code> types, respectively. <a href="#fnref:arc" class="reversefootnote" role="doc-backlink">&#8617;</a></p> </li> <li id="fn:src" role="doc-endnote"> <p>This is the file: <a href="https://github.com/mcy/alkyne/blob/a62ad3b7ee70268625da640c1edeea8ff7116512/src/eval2/gc.rs">https://github.com/mcy/alkyne/blob/a62ad3b7ee70268625da640c1edeea8ff7116512/src/eval2/gc.rs</a>. It’s got fairly complete comments, but they’re written for an audience familiar with allocators and garbage collectors. <a href="#fnref:src" class="reversefootnote" role="doc-backlink">&#8617;</a></p> </li> <li id="fn:max-size" role="doc-endnote"> <p>Currently Alkyne has a rather small max ream size. A better way to approach this would be to treat the entire heap as one gigantic ream at the start, which is always at the bottom of the free list. <a href="#fnref:max-size" class="reversefootnote" role="doc-backlink">&#8617;</a></p> </li> <li id="fn:stack-roots" role="doc-endnote"> <p>In GC terms, these are often called “stack roots”. <a href="#fnref:stack-roots" class="reversefootnote" role="doc-backlink">&#8617;</a></p> </li> <li id="fn:interpreter-knowledge" role="doc-endnote"> <p>The interpreter simply knows this and can instruct the GC appropriately. In any tracing GC, the compiler or interpreter must be keenly aware of the layouts of types so that it can generate the appropriate tracing code for each.</p> <p>This is why grafting GCs to non-GC’d languages is non-trivial, even though people have totally done it: <a href="https://www.hboehm.info/gc/">libboehm</a> and <a href="https://chromium.googlesource.com/chromium/src/+/master/third_party/blink/renderer/platform/heap/BlinkGCAPIReference.md">Oilpan</a> are good examples. <a href="#fnref:interpreter-knowledge" class="reversefootnote" role="doc-backlink">&#8617;</a></p> </li> <li id="fn:if-quick-kill" role="doc-endnote"> <p>With “instant apocalypse”, this isn’t quite true; after two mark phases, pages from the first mark phase will appear to be alive, since the global “alive” convention has changed twice. Thus, only pages condemned in every other mark phase will be swept; sweeping is most optimal after an odd number of marks. <a href="#fnref:if-quick-kill" class="reversefootnote" role="doc-backlink">&#8617;</a></p> </li> </ol> </div> </div> <div class="related post-footer"> <h2>Related Posts</h2> <ul class="related-posts"> <li> <a href="/2021/12/19/move-ctors-2/"> <small class="post-meta-flat">2021-12-19</small> Move Constructors Revisited </a> <li> <a href="/2021/11/29/assembly-1/"> <small class="post-meta-flat">2021-11-29</small> Understanding Assembly Part I: RISC-V </a> <li> <a href="/2021/06/01/linker-script/"> <small class="post-meta-flat">2021-06-01</small> Everything You Never Wanted To Know About Linker Script </a> </ul> </div> </div> </body> <div class="sidebar show-if-mobile"> <div class="container sidebar-sticky"> &copy; 2022 Miguel Young de la Sota <br/> <a href="https://creativecommons.org/licenses/by-sa/4.0/legalcode">CC BY-SA</a> </div> </div> </html>