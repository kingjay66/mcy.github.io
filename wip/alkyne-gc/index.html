<!DOCTYPE html> <html lang="en-us"> <head> <link href="http://gmpg.org/xfn/11" rel="profile"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <meta http-equiv="content-type" content="text/html; charset=utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1"> <title> The Alkyne GC &middot; mcyoung </title> <link rel="stylesheet" href="https://mcyoung.xyz/public/css/syntax.css"> <link rel="stylesheet" href="https://mcyoung.xyz/public/css/style.css"> <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=PT+Sans:400,400italic,700|Abril+Fatface"> <link rel="shortcut icon" href="https://mcyoung.xyz/public/favicon.ico"> <link rel="alternate" type="application/rss+xml" title="RSS" href="/atom.xml"> </head> <body> <div class="sidebar"> <a href="https://mcyoung.xyz/"> <img src="https://mcyoung.xyz/public/avatar.png" alt="Yeah, I drew this. Check out my art blog." class="hide-if-mobile"/> </a> <div class="container sidebar-sticky"> <div class="sidebar-about"> <h1><a href="https://mcyoung.xyz/"> mcyoung </a></h1> <p class="lead hide-if-mobile">I'm Miguel. I write about questionable C++ and Rust code. I also have an art blog linked below. </p> </div> <hr class="hide-if-mobile"/> <nav class="sidebar-nav"> <a class="sidebar-nav-item" href="https://mcyoung.xyz/">Home</a> • <a class="sidebar-nav-item" href="/about.html">About</a> • <a class="sidebar-nav-item" href="/posts.html">Posts</a> • <a class="sidebar-nav-item" href="/tags.html">Tags</a> </nav> <nav class="sidebar-nav"> <a class="sidebar-nav-item" href="https://art.mcyoung.xyz/">Art</a> • <a class="sidebar-nav-item" href="https://github.com/mcy">GH</a> • <a class="sidebar-nav-item" href="https://twitter.com/DrawsMiguel">Twt</a> • <a class="sidebar-nav-item" href="https://mcyoung.xyz/public/resume.pdf">Resumé</a> </nav> <br class="hide-if-mobile"/> <p class="hide-if-mobile">&copy; 2022 Miguel Young de la Sota <br/> <a href="https://creativecommons.org/licenses/by-sa/4.0/legalcode">CC BY-SA</a></p> </div> </div> <div class="content container"><div class="post"> <span class="post-meta"> <span> <a href="https://mcyoung.xyz/tags.html#dark-arts">#dark-arts</a> <a href="https://mcyoung.xyz/tags.html#pointers">#pointers</a> </span> <span> Soon™ </span> </span> <h1 class="post-title"><a href="/wip/alkyne-gc/"> The Alkyne GC </a></h1> <p><a href="https://github.com/mcy/alkyne">Alkyne</a> is a scripting language I built a couple of years ago for generating configuration blobs. Its interpreter is a naive AST walker<sup id="fnref:ast-walker" role="doc-noteref"><a href="#fn:ast-walker" class="footnote" rel="footnote">1</a></sup> that uses ARC<sup id="fnref:arc" role="doc-noteref"><a href="#fn:arc" class="footnote" rel="footnote">2</a></sup></p> <p>just walks the AST and uses ARC for memory management, so it’s pretty slow, and I’ve been gradually writing a <a href="https://github.com/mcy/alkyne/tree/new-engine">new evaluation engine</a> for it.</p> <p>This post isn’t about Alkyne itself, that’s for another day. I want to write down some notes for the GC I wrote<sup id="fnref:src" role="doc-noteref"><a href="#fn:src" class="footnote" rel="footnote">3</a></sup> for it, and more generally provide an introduction to memory allocators.</p> <blockquote> <p>If you want to read about something totally nuts, take a look at <a href="https://google.github.io/tcmalloc/design.html">TCMalloc’s design doc</a>. I am far from an expert on concurrent allocators; Alkyne is intended to be single-threaded, which makes the design much more approachable.</p> </blockquote> <h2 id="a-heap-of-trouble"><a href="#a-heap-of-trouble">A Heap of Trouble</a></h2> <p>To build a garbage collector, we first need to build an allocator. One can “just” use the system heap as a source of pages, but we can do better by side-stepping it completely.</p> <p>A memory heap (not to be confused with a min-heap, a completely unrelated data structure) is a random-access pool that programs can acquire indefinite-length leases of space to do whatever they want with. Its API is, in its most common form, is</p> <div class="codeblock"><figure class="highlight"><pre><code class="language-c--" data-lang="c++"><span class="k">class</span> <span class="nc">Allocator</span> <span class="p">{</span>
 <span class="nl">public:</span>
  <span class="c1">// Returns a *unique pointer* managed by this allocator</span>
  <span class="c1">// to memory as large as requested.</span>
  <span class="c1">// </span>
  <span class="c1">// Returns `nullptr` on failure.</span>
  <span class="kt">void</span><span class="o">*</span> <span class="n">Alloc</span><span class="p">(</span><span class="kt">size_t</span> <span class="n">size</span><span class="p">);</span>
  <span class="c1">// Frees a pointer returned by `Alloc` may be called at</span>
  <span class="c1">// most once.</span>
  <span class="kt">void</span> <span class="n">Free</span><span class="p">(</span><span class="kt">void</span><span class="o">*</span> <span class="n">ptr</span><span class="p">);</span>
<span class="p">};</span></code></pre></figure><div class="codeblock-buttons"><div class="codeblock-button">C++</div></div></div> <p>For simplicity, we will pretend pointer alignment does not exist, nor will we talk about “sized delete”, i.e., a version of <code class="language-plaintext highlighter-rouge">Free()</code> that accepts a size.</p> <h3 id="really-implementing-malloc-is-trivial"><a href="#really-implementing-malloc-is-trivial">Really, Implementing <code class="language-plaintext highlighter-rouge">malloc()</code> is Trivial</a></h3> <p>Allocating memory is actually very easy. Arenas are the leanest and meanest in the allocator food chain; they simply don’t implement <code class="language-plaintext highlighter-rouge">Free()</code>:</p> <div class="codeblock"><figure class="highlight"><pre><code class="language-c--" data-lang="c++"><span class="k">class</span> <span class="nc">Bump</span> <span class="p">{</span>
 <span class="nl">public:</span>
  <span class="kt">void</span><span class="o">*</span> <span class="n">Alloc</span><span class="p">(</span><span class="kt">size_t</span> <span class="n">size</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">memory_</span><span class="p">.</span><span class="n">size</span><span class="p">()</span> <span class="o">-</span> <span class="n">cursor_</span> <span class="o">&lt;</span> <span class="n">size</span><span class="p">)</span> <span class="p">{</span>
      <span class="k">return</span> <span class="nb">nullptr</span><span class="p">;</span>
    <span class="p">}</span>
    <span class="k">auto</span> <span class="n">cursor</span> <span class="o">=</span> <span class="n">cursor_</span><span class="p">;</span>
    <span class="n">cursor_</span> <span class="o">+=</span> <span class="n">size</span><span class="p">;</span>
    <span class="k">return</span> <span class="o">&amp;</span><span class="n">memory_</span><span class="p">[</span><span class="n">cursor</span><span class="p">];</span>
  <span class="p">}</span>
  <span class="kt">void</span> <span class="n">Free</span><span class="p">(</span><span class="kt">void</span><span class="o">*</span> <span class="n">ptr</span><span class="p">)</span> <span class="p">{</span>
    <span class="c1">// Nothing. :)</span>
  <span class="p">}</span>
 <span class="nl">private:</span>
  <span class="n">std</span><span class="o">::</span><span class="n">span</span><span class="o">&lt;</span><span class="kt">char</span><span class="o">&gt;</span> <span class="n">memory_</span><span class="p">;</span>
  <span class="kt">size_t</span> <span class="n">cursor_</span><span class="p">;</span>
<span class="p">};</span></code></pre></figure><div class="codeblock-buttons"><div class="codeblock-button">C++</div></div></div> <p>Of course, the memory needs to come from <em>somewhere</em>. For arenas, this is usually <code class="language-plaintext highlighter-rouge">malloc()</code>; on construction they call <code class="language-plaintext highlighter-rouge">malloc(kReallyBig)</code>, and on destruction <code class="language-plaintext highlighter-rouge">free(memory_.data())</code>. The system allocator (on a Unix like Linux) almost certainly gets its memory from <a href="https://man7.org/linux/man-pages/man2/mmap.2.html"><code class="language-plaintext highlighter-rouge">mmap()</code></a>, which <em>itself</em> calls into the kernel’s page allocator that actually sections off physical RAM for you<sup id="fnref:lazy-alloc" role="doc-noteref"><a href="#fn:lazy-alloc" class="footnote" rel="footnote">4</a></sup>.</p> <p>In theory, all of these could be arenas; arenas are not actually useless! They’re great for holding onto data that exists for the context of a “session”, such as for software that does lots of computations and then exits (a compiler) or software that handles requests from clients (a webserver).</p> <p>They are not, however, good for long-running systems. Eventually the buffer will be exhausted if you cannot free memory. This turns out to be hard<sup>[citation-needed]</sup>. This is the “fundamental theorem” of allocators:</p> <blockquote> <h4 id="fundamental-theorem-of-allocators"><a href="#fundamental-theorem-of-allocators">Fundamental “Theorem” of Allocators</a></h4> <p>Efficiently recycling memory is hard.</p> </blockquote> <p>Thankfully, over the last fifty years we’ve mostly figured this out.</p> <h2 id="baby-steps"><a href="#baby-steps">Baby Steps</a></h2> <p>From here, we will gradually augment our arena design with more features to allow it to service all kinds of requests.</p> <h3 id="blocks-and-free-lists"><a href="#blocks-and-free-lists">Blocks and Free Lists</a></h3> <p>The core abstraction of every allocator is to break up the address space it is managing into uniform(ish) <em>blocks</em> of a convenient size. Each block will have some metadata attached to it. Blocks are organized into one or more <em>free lists</em> (stacks, effectively) of unused blocks, that can be cheaply pushed and popped from. Thus, we can enhance our arena above with a free list, making it a proper allocator:</p> <div class="codeblock"><figure class="highlight"><pre><code class="language-c--" data-lang="c++"><span class="k">class</span> <span class="nc">FreeList</span> <span class="p">{</span>
 <span class="nl">public:</span>
  <span class="k">static</span> <span class="k">constexpr</span> <span class="kt">size_t</span> <span class="n">kMaxSize</span> <span class="o">=</span> <span class="mi">128</span><span class="p">;</span>
  <span class="kt">void</span><span class="o">*</span> <span class="n">Alloc</span><span class="p">(</span><span class="kt">size_t</span> <span class="n">size</span><span class="p">)</span> <span class="p">{</span>
    <span class="c1">// We can only serve a maximum size.</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">blocks_</span><span class="p">.</span><span class="n">empty</span><span class="p">()</span> <span class="o">||</span> <span class="n">size</span> <span class="o">&gt;</span> <span class="n">kMaxSize</span><span class="p">)</span> <span class="p">{</span>
      <span class="k">return</span> <span class="nb">nullptr</span><span class="p">;</span>
    <span class="p">}</span>

    <span class="n">Block</span><span class="o">*</span> <span class="n">block</span> <span class="o">=</span> <span class="n">free_list_</span><span class="p">.</span><span class="n">back</span><span class="p">();</span>
    <span class="n">block</span><span class="o">-&gt;</span><span class="n">is_free</span> <span class="o">=</span> <span class="nb">false</span><span class="p">;</span>
    <span class="n">free_list_</span><span class="p">.</span><span class="n">pop</span><span class="p">();</span>

    <span class="k">return</span> <span class="n">block</span><span class="o">-&gt;</span><span class="n">data</span><span class="p">.</span><span class="n">data</span><span class="p">();</span>
  <span class="p">}</span>

  <span class="kt">void</span> <span class="n">Free</span><span class="p">(</span><span class="kt">void</span><span class="o">*</span> <span class="n">ptr</span><span class="p">)</span> <span class="p">{</span>
    <span class="c1">// Assume ptr one of ours; offset past the header.</span>
    <span class="n">Block</span><span class="o">*</span> <span class="n">block</span> <span class="o">=</span> <span class="k">reinterpret_cast</span><span class="o">&lt;</span><span class="n">Block</span><span class="o">*&gt;</span><span class="p">(</span>
      <span class="k">reinterpret_cast</span><span class="o">&lt;</span><span class="kt">char</span><span class="o">*&gt;</span><span class="p">(</span><span class="n">ptr</span><span class="p">)</span> <span class="o">-</span> <span class="n">offsetof</span><span class="p">(</span><span class="n">Block</span><span class="p">,</span> <span class="n">data</span><span class="p">));</span>

    <span class="c1">// We do a probabilistic check here as an imperfect</span>
    <span class="c1">// defense against double-free; lots of allocators</span>
    <span class="c1">// do this.</span>
    <span class="n">assert</span><span class="p">(</span><span class="o">!</span><span class="n">block</span><span class="o">-&gt;</span><span class="n">is_free</span><span class="p">);</span>

    <span class="n">block</span><span class="o">-&gt;</span><span class="n">is_free</span> <span class="o">=</span> <span class="nb">true</span><span class="p">;</span>
    <span class="n">free_list_</span><span class="p">.</span><span class="n">push_back</span><span class="p">(</span><span class="n">block</span><span class="p">);</span>
  <span class="p">}</span>

 <span class="nl">private:</span>
  <span class="c1">// The block can contain header information in addition</span>
  <span class="c1">// to user-visible data. </span>
  <span class="k">struct</span> <span class="nc">Block</span> <span class="p">{</span>
    <span class="kt">bool</span> <span class="n">is_free</span><span class="p">;</span>
    <span class="n">std</span><span class="o">::</span><span class="n">array</span><span class="o">&lt;</span><span class="kt">char</span><span class="p">,</span> <span class="n">kMaxSize</span><span class="o">&gt;</span> <span class="n">data</span><span class="p">;</span>
  <span class="p">};</span>

  <span class="c1">// Backing store; never resized.</span>
  <span class="n">std</span><span class="o">::</span><span class="n">span</span><span class="o">&lt;</span><span class="n">Block</span><span class="o">&gt;</span> <span class="n">blocks_</span><span class="p">;</span>
  <span class="c1">// Contains a block if and only if it is not allocated.</span>
  <span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">Block</span><span class="o">*&gt;</span> <span class="n">free_list_</span><span class="p">;</span>
<span class="p">};</span></code></pre></figure><div class="codeblock-buttons"><div class="codeblock-button">C++</div></div></div> <p>Allocation and freeing is O(1), yay! There are, however, serious limitations:</p> <ul> <li>We need to call an allocator to allocate the free list.</li> <li>Blocks are exactly 128 bytes; small allocations are wasteful while large ones can’t be serviced!</li> </ul> <p>The first of these is easily resolved by making the free list a linked list! The much-derided linked list is actually an extremely popular data structure for use in allocators; with a few tweaks, we can drop the separate free list by making it part of the block store.</p> <div class="codeblock"><figure class="highlight"><pre><code class="language-c--" data-lang="c++"><span class="k">class</span> <span class="nc">KnRAlloc</span> <span class="p">{</span>
 <span class="nl">public:</span>
  <span class="k">static</span> <span class="k">constexpr</span> <span class="kt">size_t</span> <span class="n">kMaxSize</span> <span class="o">=</span> <span class="mi">128</span><span class="p">;</span>
  <span class="n">FreeList2</span><span class="p">()</span> <span class="p">{</span>
    <span class="n">blocks_</span> <span class="o">=</span> <span class="cm">/* mmap() or something */</span><span class="p">;</span>

    <span class="c1">// To construct the list, we need to mark every block as freed.</span>
    <span class="k">for</span> <span class="p">(</span><span class="n">Block</span><span class="o">*</span> <span class="n">b</span> <span class="o">:</span> <span class="n">blocks_</span><span class="p">)</span> <span class="p">{</span>
      <span class="n">Free</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="p">{});</span>
    <span class="p">}</span>
  <span class="p">}</span>

  <span class="kt">void</span><span class="o">*</span> <span class="n">Alloc</span><span class="p">(</span><span class="kt">size_t</span> <span class="n">size</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">free_list_</span> <span class="o">==</span> <span class="nb">nullptr</span> <span class="o">||</span> <span class="n">size</span> <span class="o">&gt;</span> <span class="n">kMaxSize</span><span class="p">)</span> <span class="p">{</span>
      <span class="k">return</span> <span class="nb">nullptr</span><span class="p">;</span>
    <span class="p">}</span>

    <span class="c1">// To allocate, we unlink the list head.</span>
    <span class="n">Block</span><span class="o">*</span> <span class="n">block</span> <span class="o">=</span> <span class="n">free_list_</span><span class="p">;</span>
    <span class="n">free_list_</span> <span class="o">=</span> <span class="n">free_list_</span><span class="o">-&gt;</span><span class="n">next</span><span class="p">;</span>
    <span class="n">block</span><span class="o">-&gt;</span><span class="n">next</span> <span class="o">=</span> <span class="nb">nullptr</span><span class="p">;</span>
    <span class="k">return</span> <span class="n">block</span><span class="p">;</span>
  <span class="p">}</span>

  <span class="kt">void</span> <span class="n">Free</span><span class="p">(</span><span class="kt">void</span><span class="o">*</span> <span class="n">ptr</span><span class="p">,</span> <span class="n">Layout</span> <span class="n">layout</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">Block</span><span class="o">*</span> <span class="n">block</span> <span class="o">=</span> <span class="cm">/* as before */</span><span class="p">;</span>
    <span class="n">assert</span><span class="p">(</span><span class="n">block</span><span class="o">-&gt;</span><span class="n">next</span> <span class="o">==</span> <span class="nb">nullptr</span><span class="p">);</span>

    <span class="c1">// To free, link the block back in.</span>
    <span class="n">block</span><span class="o">-&gt;</span><span class="n">next</span> <span class="o">=</span> <span class="n">free_list_</span><span class="p">;</span>
    <span class="n">free_list_</span> <span class="o">=</span> <span class="n">block</span><span class="p">;</span>
  <span class="p">}</span>

 <span class="nl">private:</span>
  <span class="c1">// The block can contain header information in addition</span>
  <span class="c1">// to user-visible data. </span>
  <span class="k">struct</span> <span class="nc">Block</span> <span class="p">{</span>
    <span class="n">Block</span><span class="o">*</span> <span class="n">next</span><span class="p">;</span>
    <span class="n">std</span><span class="o">::</span><span class="n">array</span><span class="o">&lt;</span><span class="kt">char</span><span class="p">,</span> <span class="n">kMaxSize</span><span class="o">&gt;</span> <span class="n">data</span><span class="p">;</span>
  <span class="p">};</span>

  <span class="c1">// Backing store; never resized.</span>
  <span class="n">std</span><span class="o">::</span><span class="n">span</span><span class="o">&lt;</span><span class="n">Block</span><span class="o">&gt;</span> <span class="n">blocks_</span><span class="p">;</span>
  <span class="n">Block</span><span class="o">*</span> <span class="n">free_list_</span> <span class="o">=</span> <span class="nb">nullptr</span><span class="p">;</span>
<span class="p">};</span></code></pre></figure><div class="codeblock-buttons"><div class="codeblock-button">C++</div></div></div> <p>The <code class="language-plaintext highlighter-rouge">free_list_</code> data structure is called an <em>intrusive linked list</em>. Elements of the list contain a pointer to the next element, rather than having it be allocated on the side. This allows a flat array of elements to double as a backing store and a stack!</p> <p>This design is a simplified version of the one found in the K&amp;R book, but it suffers from the size issue: it can’t allocate more than 128 bytes, and that’s super wasteful if you allocate small amounts!</p> <p>At this point it makes sense to dive into how Alkyne achieves this; there are <em>many</em> choices for how to do this; Alkyne is based off of things I wanted to try out at the time.</p> <p>(At this point, I won’t provide more code samples; I suggest referring to the Alkyne source, instead.)</p> <h3 id="block-splitting-the-alkyne-way"><a href="#block-splitting-the-alkyne-way">Block Splitting, the Alkyne Way</a></h3> <p>The next step is to use a block splitting/merging scheme, such as the <a href="https://en.wikipedia.org/wiki/Buddy_memory_allocation"><em>buddy system</em></a>. Alkyne does not use the buddy system, since it is a garbage-collecting heap, but it does do something similar.</p> <p>Most allocators, including Alkyne, define a <em>page</em> as the minimum quantity of memory that they operate on. For Alkyne, this is a 4K operating system page; TCMalloc, which mostly uses hugepages that are much larger than that, has 8K pages.</p> <p>We maintain a giant “main” free list of <em>reams</em>, which are blocks of two or more contiguous pages. Each ream tracks the number of blocks in it, and is used kind of like an arena. When N pages are requested:</p> <ul> <li>We walk through the free ream list, and pick the first one with at least N pages.</li> <li>We “split” it: the first N pages are returned to fulfill the request.</li> <li>The rest of the ream is put back into the free list.</li> <li>If no such ream exists, we allocate a max-sized ream (65536 pages, or about 260K in Alkyne’s case), and split that as above.</li> </ul> <p>To free a ream, we put it back on the main free list.</p> <p>Allocation headers can’t be contiguous with reams, since reams can be of dynamic length. Thus, Alkyne maintains a separate array of <em>page descriptors</em>, (called <a href="https://github.com/mcy/alkyne/blob/a62ad3b7ee70268625da640c1edeea8ff7116512/src/eval2/gc.rs#L416"><code class="language-plaintext highlighter-rouge">Pd</code></a>s) which are per-page book-keeping. This is where the length of a ream, as well as the intrusive linked-list pointers, live. A ream’s <code class="language-plaintext highlighter-rouge">Pd</code> is the <code class="language-plaintext highlighter-rouge">Pd</code> of the first page in the ream.</p> <p>There is an obvious problem: Over time, reams will get smaller and smaller, and fragmentation will make further allocation of large blocks impossible. As of writing I have not implemented this, but there are a few ways to resolve it.</p> <p>Pages and their descriptors are allocated on the Alkyne heap such that the address of the descriptor can be computed from the address of the page (i.e., the page <code class="language-plaintext highlighter-rouge">pages[n]</code> is described by <code class="language-plaintext highlighter-rouge">pd[n]</code>). This means that we can merge contiguous reams by:</p> <ul> <li>Find two adjacent, unallocated reams (each <code class="language-plaintext highlighter-rouge">Pd</code> contains the number of pages in the ream so skipping over a ream is O(1)).</li> <li>Remove the second ream from its free list and reset its <code class="language-plaintext highlighter-rouge">Pd</code>.</li> <li>Grow the first ream by the number of pages in the second.</li> </ul> <p>We can apply this compaction operation either periodically on the whole heap (iterating over the entire <code class="language-plaintext highlighter-rouge">Pd</code> array on <code class="language-plaintext highlighter-rouge">Free()</code> every once in a while) or by trying to merge a newly-freed ream with the two reams adjacent to it (this requires extra book-keeping to find the start of the previous ream in the <code class="language-plaintext highlighter-rouge">Pd</code> array).</p> <p>The choice of which makes sense depends on whether you’re implementing a garbage collector or an ordinary heap (we’ll see why later). This is a big reason why you want to rely as little as possible on your system malloc if you’re building a GC!</p> <h3 id="slabs-and-size-classes"><a href="#slabs-and-size-classes">Slabs and Size Classes</a></h3> <p>A <em>slab allocator</em> is a specialized allocator that allocates a single type of object; they are quite popular in kernels as pools of commonly-used object types. The crux of a slab allocator is because everything is the same size, we <em>don’t</em> need to implement splitting and merging. If you only need to allocate <code class="language-plaintext highlighter-rouge">int</code>s, why bother? Our <code class="language-plaintext highlighter-rouge">Pd</code> array is kind of like a slab allocator; instead of mixing them in with the variably-sized blocks, they all live together with no gaps in between; entire pages are dedicated just to <code class="language-plaintext highlighter-rouge">Pd</code>s.</p> <p>The Alkyne page allocator cannot allocate pages smaller than 4K, and making them any smaller increases the relative overhead of a <code class="language-plaintext highlighter-rouge">Pd</code>; this is why TCMalloc uses pages larger than system pages! To minimize waste, we can use slab allocation for small objects by defining <em>size classes</em>.</p> <p>Alkyne’s size classes are powers of two from 8 to 2048. Every allocation smaller than a page is rounded up to one of these; a separate “small” free list is maintained for <em>each</em> size class; additionally there is a “page” free list consisting of single pages not part of a larger ream.</p> <p>Each small object page is an array of <code class="language-plaintext highlighter-rouge">4096/N</code><sup id="fnref:very-small-pages" role="doc-noteref"><a href="#fn:very-small-pages" class="footnote" rel="footnote">5</a></sup> objects of the same size. Pages can be partially filled; which slots are in-use is tracked by the “presence bitset” in the <code class="language-plaintext highlighter-rouge">Pd</code> (called the <code class="language-plaintext highlighter-rouge">gc_bits</code>, since they are used for garbage collection, too). Partially-filled pages live in the free list.</p> <p>To allocate a small object, we grab the first list on the appropriate free list (we don’t need too walk it; the first one is guaranteed to have space). We then search the presence bits for an empty slot (a very fast, SIMD-able operation). Once we find it, we set it as occupied and compute the appropriate offset into the page and return that memory.</p> <p>If the free list is empty, we can grab an empty page from the page list and make it into a small object page; we can also use this free list for servicing things that are larger than half a page.</p> <p>Freeing small objects is tricky, since we do not a priori know the size. If we assume the pointer is the start of an allocation, we can find its <code class="language-plaintext highlighter-rouge">Pd</code>, regardless of whether it is small, by rounding down to a page boundary, finding the page index, and using that to find the <code class="language-plaintext highlighter-rouge">Pd</code> (due to the correspondence described above). If it is a small object <code class="language-plaintext highlighter-rouge">Pd</code>, we can use the original pointer to deduce the index of the value, and clear its presence bit.</p> <p>If the page was previously full, it goes into the relevant freelist; if we completely empty the page, it goes into the empty page list.</p> <p>Size classes are an important allocator optimization. TCMalloc takes this to an <a href="https://github.com/google/tcmalloc/blob/master/tcmalloc/size_classes.cc">comical extreme</a>.</p> <h2 id="getting-rid-of-free"><a href="#getting-rid-of-free">Getting Rid of <code class="language-plaintext highlighter-rouge">Free()</code></a></h2> <p>Now that we have a fully functioning <code class="language-plaintext highlighter-rouge">Free()</code>, we need to rethink it from the ground up to play nice with a <em>garbage collector</em>.</p> <p>Garbage collection is very different from manual memory management in that frees are performed in batches by an omniscient system. There are no calls to <code class="language-plaintext highlighter-rouge">Free()</code>; instead, we need to figure out which calls to <code class="language-plaintext highlighter-rouge">Free()</code> we <em>can</em> make on the user’s behalf that they won’t notice (i.e., without quietly freeing pointers the user can still reach, resulting in a use-after-free bug).</p> <p>Alkyne is a tracing GC that follows the <em>mark and sweep</em> design. The “object graph” describes which objects are <em>reachable</em> from other objects; <code class="language-plaintext highlighter-rouge">a</code> is reachable directly from <code class="language-plaintext highlighter-rouge">b</code> if <code class="language-plaintext highlighter-rouge">b</code> contains a pointer to <code class="language-plaintext highlighter-rouge">a</code>.</p> <p><em>Marking</em> consists of traversing the entire graph from a collection of reachable-by-definition values, such as things on the stack, and recording each object that is visited. Every object <em>not</em> so marked must therefore be definitely unreachable and can be reclaimed. Rooting through the heap to find unmarked “zombie” objects is called <em>sweeping</em>.</p> <p>Alkyne reverses the order of operations somewhat: it “sweeps” first and then marks, i.e., it marks every value as dead and then, as it walks the graph, marks every block as alive. It then rebuilds the free lists to reflect the new marks, allowing the blocks to be reallocated. This is sometimes called “mark and don’t sweep”, but fixing up the free lists is effectively a sweeping step.</p> <h3 id="heap-armageddon-and-resurrection"><a href="#heap-armageddon-and-resurrection">Heap Armageddon and Resurrection</a></h3> <p>Delicate freeing of single objects is quite difficult, but scorching the earth is very easy. To do this, we walk the whole <code class="language-plaintext highlighter-rouge">Pd</code> array and clear every presence bit[^quick-kill]. This leaves the heap in a broken state where every pointer appears to be dangling. This is “armageddon”.</p> <p>To fix this up, we need to “resurrect” any objects we shouldn’t have killed. The roots are objects in the Alkyne interpreter stack<sup id="fnref:stack-roots" role="doc-noteref"><a href="#fn:stack-roots" class="footnote" rel="footnote">6</a></sup>. To mark an object, we convert a pointer to it into a <code class="language-plaintext highlighter-rouge">Pd</code> via the page-<code class="language-plaintext highlighter-rouge">Pd</code> correspondence, and mark it as alive by “allocating” it.</p> <p>At the end of this process, every reachable object will once again be alive, but anything we couldn’t reach stays dead.</p> <h3 id="instant-apocalypse"><a href="#instant-apocalypse">Instant Apocalypse</a></h3> <p>Alkyne currently does not make this optimization, but probably should:</p> <p>Rather than flipping every bit, we flip the global <em>convention</em> for whether 0 or 1 means “alive”, implemented by having a global <code class="language-plaintext highlighter-rouge">bool</code> specifying which is which at any given time; this would alternate from sweep to sweep. Thus, killing every living object is O(1), not O(heap).</p> <p>This works if the allocated bit of things in the free lists is never read, and only ever overwritten with the “alive” value when allocated, so that all of the dead objects suddenly becoming alive isn’t noticed. This does not work with slab-allocated small objects: pages may be in a mixed state where they are partially allocated and partially freed.</p> <p>We can still make this optimization by adding a second bit that tracks whether the page contains <em>any</em> living objects, using the same convention. This allows delaying the clear of the allocated bits for small objects to when the page is visited, which also marks the whole page as alive.</p> <p>Pages that were never visited (i.e., still marked as dead) can be reclaimed as usual, ignoring the allocated bits.</p> <h3 id="free-list-reconciliation"><a href="#free-list-reconciliation">Free List Reconciliation</a></h3> <p>At this point, no pointers are dangling, but newly emptied out pages are not in the free lists they should be in. To fix this, we can walk over all <code class="language-plaintext highlighter-rouge">Pd</code>s and put them where they need to go if they’re not full. This is the kinda-but-not-really sweep phase.</p> <p>The Rust code is surprisingly simple:</p> <div class="codeblock"><figure class="highlight"><pre><code class="language-rust" data-lang="rust"><span class="k">for</span> <span class="n">pd</span> <span class="n">in</span> <span class="k">self</span><span class="py">.raw</span><span class="nf">.pds</span><span class="p">()</span><span class="nf">.filter</span><span class="p">(|</span><span class="n">pd</span><span class="p">|</span> <span class="n">pd</span><span class="nf">.is_linked</span><span class="p">())</span> <span class="p">{</span>
  <span class="k">if</span> <span class="n">pd</span><span class="nf">.is_empty</span><span class="p">()</span> <span class="p">{</span>
    <span class="n">pd</span><span class="nf">.unlink</span><span class="p">();</span>
    <span class="k">if</span> <span class="n">pd</span><span class="nf">.is_single_page</span><span class="p">()</span> <span class="p">{</span>
      <span class="k">unsafe</span> <span class="p">{</span> <span class="k">self</span><span class="py">.page_free_list</span><span class="nf">.push</span><span class="p">(</span><span class="n">pd</span><span class="p">)</span> <span class="p">}</span>
    <span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
      <span class="k">unsafe</span> <span class="p">{</span> <span class="k">self</span><span class="py">.ream_free_list</span><span class="nf">.push</span><span class="p">(</span><span class="n">pd</span><span class="p">)</span> <span class="p">}</span>
    <span class="p">}</span>
  <span class="p">}</span> <span class="k">else</span> <span class="k">if</span> <span class="n">pd</span><span class="nf">.is_full</span><span class="p">()</span> <span class="p">{</span>
    <span class="c">// GC can't make a not-full-list become full, so we don't</span>
    <span class="c">// need to move it.</span>
  <span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
    <span class="c">// Non-empty, non-full lists cannot be reams.</span>
    <span class="nd">debug_assert!</span><span class="p">(</span><span class="n">pd</span><span class="nf">.class</span><span class="p">()</span> <span class="o">!=</span> <span class="nn">SizeClass</span><span class="p">::</span><span class="n">Ream</span><span class="p">);</span>

    <span class="n">pd</span><span class="nf">.unlink</span><span class="p">();</span>
    <span class="k">unsafe</span> <span class="p">{</span>
      <span class="k">self</span><span class="py">.sized_free_lists</span><span class="p">[</span><span class="n">pd</span><span class="nf">.class</span><span class="p">()</span> <span class="k">as</span> <span class="nb">usize</span> <span class="o">-</span> <span class="mi">3</span><span class="p">]</span><span class="nf">.push</span><span class="p">(</span><span class="n">pd</span><span class="p">)</span>
    <span class="p">}</span>
  <span class="p">}</span>
<span class="p">}</span></code></pre></figure><div class="codeblock-buttons"><div class="codeblock-button">Rust</div></div></div> <p>Of course, this will also shuffle around all pages that did not become partially empty or empty while marking. If the “instant apocalypse” optimization is used, this step must still inspect every <code class="language-plaintext highlighter-rouge">Pd</code> and modify the free lists.</p> <p>However, it is a completely separate phase: all it does is find pages that did not survive the previous mark phase. This means that user code can run between the phases, reducing latency. If it turns out to be very expensive to sweep the whole heap, it can even be run less often than mark phases<sup id="fnref:if-quick-kill" role="doc-noteref"><a href="#fn:if-quick-kill" class="footnote" rel="footnote">7</a></sup>.</p> <p>…and that’s it! That’s garbage collection. The setup of completely owning the layout of blocks in the allocator allows us to cut down significantly on memory needed to track objects in the heap, while keeping the mark and sweep steps short and sweet. A garbage collector is like any other data structure: you pack in a lot of complexity into the invariants to make the actual operations very quick.</p> <h2 id="conclusion"><a href="#conclusion">Conclusion</a></h2> <p>Alkyne’s GC is intended to be super simple because I didn’t want to think too hard about it. The GC layouts are a whole nother story I have been swirling around in my head for months, which is described <a href="https://github.com/mcy/alkyne/blob/a62ad3b7ee70268625da640c1edeea8ff7116512/src/eval2/value.rs#L78">here</a>. The GC design does not take advantage of the fact that the new Alkyne VM is 32-bit, but the layout of values does very aggressively, and takes advantage of several features of the GC.</p> <h3 id="finalizers-tools-of-the-devil"><a href="#finalizers-tools-of-the-devil">Finalizers (Tools of the Devil)</a></h3> <p>Alkyne also does not provide finalizers. A finalizer is the GC equivalent of a destructor: it gets run after the GC declares an object dead. Finalizers complicate a GC significantly by their very nature; they are called in unspecified orders and can witness broken GC state; they can stall the entire program (if they are implemented to run during the GC pause in a multi-threaded GC) or else need to be called with a zombie argument that either can’t escape the finalizer or, worse, must be resurrected if it does!</p> <p>If finalizers depend on each other, they can’t be run at all, for the same reason an ARC cycle cannot be broken; this weakness of ARC is one of the major benefits of an omniscient GC.</p> <p>Java’s <a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/Object.html#finalize()">documentation for <code class="language-plaintext highlighter-rouge">Object.finalize()</code></a> is a wall of text of lies, damned lies, and ghost stories.</p> <p>I learned earlier (the week before writing this) that Go ALSO has finalizers and that they are <a href="https://pkg.go.dev/runtime#SetFinalizer">similarly cursed</a>. Go does behave somewhat more nicely (finalizers are per-value and avoid zombie problems by unconditionally resurrecting objects with a finalizer).</p> <h3 id="further-reading"><a href="#further-reading">Further Reading</a></h3> <p>TODO</p> <div class="footnotes" role="doc-endnotes"> <ol> <li id="fn:ast-walker" role="doc-endnote"> <p>In other words, it uses recursion along a syntax tree, instead of a more efficient approach that compiles the program down to bytecode. <a href="#fnref:ast-walker" class="reversefootnote" role="doc-backlink">&#8617;</a></p> </li> <li id="fn:arc" role="doc-endnote"> <p><em>A</em>utomatic <em>R</em>eference <em>C</em>ounting is an automatic memory management technique where every heap allocation contains a counter of how many pointers currently point to it; once pointers go out of scope, they decrement the counter; when the counter hits zero the memory is freed.</p> <p>This is used by Python and Swift as the core memory management strategy, and provided by C++ and Rust via the <code class="language-plaintext highlighter-rouge">std::shared_ptr&lt;T&gt;</code> and <code class="language-plaintext highlighter-rouge">Arc&lt;T&gt;</code> types, respectively. <a href="#fnref:arc" class="reversefootnote" role="doc-backlink">&#8617;</a></p> </li> <li id="fn:src" role="doc-endnote"> <p>This is the file: <a href="https://github.com/mcy/alkyne/blob/a62ad3b7ee70268625da640c1edeea8ff7116512/src/eval2/gc.rs">https://github.com/mcy/alkyne/blob/a62ad3b7ee70268625da640c1edeea8ff7116512/src/eval2/gc.rs</a>. It’s got fairly complete comments, but they’re written for an audience familiar with allocators and garbage collectors. <a href="#fnref:src" class="reversefootnote" role="doc-backlink">&#8617;</a></p> </li> <li id="fn:lazy-alloc" role="doc-endnote"> <p>Lazilly. On any modern system, <code class="language-plaintext highlighter-rouge">malloc(1000000000)</code> should work just fine as long as you don’t actually use too much of it. More on this later. <a href="#fnref:lazy-alloc" class="reversefootnote" role="doc-backlink">&#8617;</a></p> </li> <li id="fn:very-small-pages" role="doc-endnote"> <p>Because the presence bitset (not yet introduced) is only 64 bits, the 8, 16, and 32 byte pages have slightly less capacity, since some bits spill from the <code class="language-plaintext highlighter-rouge">Pd</code> and into the page itself. <a href="#fnref:very-small-pages" class="reversefootnote" role="doc-backlink">&#8617;</a></p> </li> <li id="fn:stack-roots" role="doc-endnote"> <p>In GC terms, these are called “stack roots”. <a href="#fnref:stack-roots" class="reversefootnote" role="doc-backlink">&#8617;</a></p> </li> <li id="fn:if-quick-kill" role="doc-endnote"> <p>With “instant apocalypse”, this isn’t quite true; after two mark phases, pages from the first mark phase will appear to be alive, since the global “alive” convention has changed twice. Thus, only pages condemned in every other mark phase will be swept; sweeping is most optimal after an odd number of marks. <a href="#fnref:if-quick-kill" class="reversefootnote" role="doc-backlink">&#8617;</a></p> </li> </ol> </div> </div> <div class="related post-footer"> <h2>Related Posts</h2> <ul class="related-posts"> <li> <a href="/2021/12/19/move-ctors-2/"> <small class="post-meta-flat">2021-12-19</small> Move Constructors Revisited </a> <li> <a href="/2021/11/29/assembly-1/"> <small class="post-meta-flat">2021-11-29</small> Understanding Assembly Part I: RISC-V </a> <li> <a href="/2021/06/01/linker-script/"> <small class="post-meta-flat">2021-06-01</small> Everything You Never Wanted To Know About Linker Script </a> </ul> </div> </div> </body> <div class="sidebar show-if-mobile"> <div class="container sidebar-sticky"> &copy; 2022 Miguel Young de la Sota <br/> <a href="https://creativecommons.org/licenses/by-sa/4.0/legalcode">CC BY-SA</a> </div> </div> </html>